é¡¹ç›® 'nova-2api' çš„ç»“æ„æ ‘:
ğŸ“‚ nova-2api/
    ğŸ“„ .env
    ğŸ“„ Dockerfile
    ğŸ“„ docker-compose.yml
    ğŸ“„ main.py
    ğŸ“„ nginx.conf
    ğŸ“„ requirements.txt
    ğŸ“‚ app/
        ğŸ“‚ core/
            ğŸ“„ __init__.py
            ğŸ“„ config.py
        ğŸ“‚ providers/
            ğŸ“„ __init__.py
            ğŸ“„ base_provider.py
            ğŸ“„ novaapp_provider.py
        ğŸ“‚ utils/
            ğŸ“„ sse_utils.py
    ğŸ“‚ static/
        ğŸ“„ index.html
        ğŸ“„ script.js
        ğŸ“„ style.css
================================================================================

--- æ–‡ä»¶è·¯å¾„: .env ---

# [è‡ªåŠ¨å¡«å……] novaapp-2api ç”Ÿäº§ç¯å¢ƒé…ç½®
# è¯¥æ–‡ä»¶ç”±é¦–å¸­æ‰§è¡Œå®˜æ¨¡å¼æ ¹æ®æ‚¨çš„æŠ“åŒ…æ•°æ®è‡ªåŠ¨ç”Ÿæˆã€‚

# --- å®‰å…¨é…ç½® ---
# ç”¨äºä¿æŠ¤æ‚¨çš„ API æœåŠ¡çš„è®¿é—®å¯†é’¥ï¼Œå»ºè®®ä¿®æ”¹ä¸ºæ‚¨è‡ªå·±çš„å¤æ‚å¯†é’¥ã€‚
API_MASTER_KEY=1

# --- éƒ¨ç½²é…ç½® ---
# Nginx å¯¹å¤–æš´éœ²çš„ç«¯å£
NGINX_PORT=8088

# --- NovaApp.ai å‡­è¯ (å·²è‡ªåŠ¨æå–æœ€æ–°ç‰ˆæœ¬) ---
# æ ¼å¼: "x_token|x_user_id"
# æ‚¨å¯ä»¥æ·»åŠ  NOVAAPP_CREDENTIAL_2, NOVAAPP_CREDENTIAL_3 ç­‰æ¥å¯ç”¨æ›´å¤šè´¦å·è½®è¯¢ã€‚
NOVAAPP_CREDENTIAL_1="eyJhbGciOiJSUzI1NiIsImtpZCI6IjlkMjEzMGZlZjAyNTg3ZmQ4ODYxODg2OTgyMjczNGVmNzZhMTExNjUiLCJ0eXAiOiJKV1QifQ.eyJuYW1lIjoic3VtbWVyIiwicGljdHVyZSI6Imh0dHBzOi8vZmlyZWJhc2VzdG9yYWdlLmdvb2dsZWFwaXMuY29tL3YwL2IvY2hhdC1haS1wcm9kLmFwcHNwb3QuY29tL28vdXNlci1hdmF0YXJzJTJGMUNYQlZwZmdrRVk0RjFidENNNFB5QTdDV1ZwMiUyRjBiOWE4OWRkLTMwZTktNGY3Zi04ZTJkLTZjOGU1ZDBiYWU3My5qcGc_YWx0PW1lZGlhJnRva2VuPTVjYWVmNWZhLTQ5OTEtNGIyMi05ODNkLTY2YTNiMmZhODY4OCIsImlzcyI6Imh0dHBzOi8vc2VjdXJldG9rZW4uZ29vZ2xlLmNvbS9jaGF0LWFpLXByb2QiLCJhdWQiOiJjaGF0LWFpLXByb2QiLCJhdXRoX3RpbWUiOjE3NjExMjgzNjMsInVzZXJfaWQiOiIxQ1hCVnBmZ2tFWTRGMWJ0Q000UHlBN0NXVnAyIiwic3ViIjoiMUNYQlZwZmdrRVk0RjFidENNNFB5QTdDV1ZwMiIsImlhdCI6MTc2MTEzNDk2NiwiZXhwIjoxNzYxMTM4NTY2LCJlbWFpbCI6ImRhdmlkYnJvd25AMTYzLmNvbSIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJmaXJlYmFzZSI6eyJpZGVudGl0aWVzIjp7ImVtYWlsIjpbImRhdmlkYnJvd25AMTYzLmNvbSJdfSwic2lnbl9pbl9wcm92aWRlciI6InBhc3N3b3JkIn19.JiDm9qqWkK0EKzykiHEQtO_r2UJSXBka1QvwdyxyP6i7zjZYPo4O2-jERikhFBPie4YwIJ3Hn_PXQcL_b2VBE5DlTpp2NjrTsV2k4qyMz-1lzHxZpe8qcRxKiaO7pmqQly9Lh5YhYZKR4d4fubJlSsup88HIw7ooINJgQRjdeCAHbQZ4oFn95kKDq0kDIwifoPSU5rOWkoUsa6epZ3nxVZjUqICOYCnSB9u5RdwzV1NqBJ7tyJv3u1cHB6Nsx4Hsmy8gYZ-Ip3wVob9sBEVhDroJjNduj7rB7ZYnd1mfEUF0gJfm1echfUaUGPL2RrcW0eiT1KvorRkH6W802EyUYg|1CXBVpfgkEY4F1btCM4PyA7CWVp2"

--- æ–‡ä»¶è·¯å¾„: Dockerfile ---

FROM python:3.10-slim

ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

COPY . .

RUN useradd --create-home appuser && \
    chown -R appuser:appuser /app
USER appuser

EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]

--- æ–‡ä»¶è·¯å¾„: docker-compose.yml ---

services:
  nginx:
    image: nginx:latest
    container_name: novaapp-2api-nginx
    restart: always
    ports:
      - "${NGINX_PORT:-8088}:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - app
    networks:
      - novaapp-net

  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: novaapp-2api-app
    restart: unless-stopped
    env_file:
      - .env
    volumes:
      - ./logs:/app/logs
    networks:
      - novaapp-net

networks:
  novaapp-net:
    driver: bridge

--- æ–‡ä»¶è·¯å¾„: main.py ---

import logging
import json
import uuid
import time
from contextlib import asynccontextmanager
from typing import Optional

from fastapi import FastAPI, Request, HTTPException, Depends, Header
from fastapi.responses import JSONResponse, StreamingResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from loguru import logger

from app.core.config import settings
from app.providers.novaapp_provider import NovaAppProvider

# --- æ—¥å¿—é…ç½® ---
logger.add(
    "logs/app.log",
    rotation="10 MB",
    retention="7 days",
    level="INFO",
    format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} - {message}"
)

# --- å…¨å±€ Provider å®ä¾‹ ---
provider = NovaAppProvider()

@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info(f"åº”ç”¨å¯åŠ¨ä¸­... {settings.APP_NAME} v{settings.APP_VERSION}")
    logger.info("æœåŠ¡å·²è¿›å…¥ 'Cloudscraper & Credential Pool' æ¨¡å¼ã€‚")
    logger.info(f"API æœåŠ¡å°†åœ¨ http://localhost:{settings.NGINX_PORT} ä¸Šå¯ç”¨")
    logger.info(f"Web UI æµ‹è¯•ç•Œé¢å·²å¯ç”¨ï¼Œè¯·è®¿é—® http://localhost:{settings.NGINX_PORT}/")
    yield
    logger.info("åº”ç”¨å…³é—­ã€‚")

app = FastAPI(
    title=settings.APP_NAME,
    version=settings.APP_VERSION,
    description=settings.DESCRIPTION,
    lifespan=lifespan
)

# --- æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½• ---
app.mount("/static", StaticFiles(directory="static"), name="static")

# --- å®‰å…¨ä¾èµ– ---
async def verify_api_key(authorization: Optional[str] = Header(None)):
    if settings.API_MASTER_KEY and settings.API_MASTER_KEY != "1":
        if not authorization or "bearer" not in authorization.lower():
            raise HTTPException(status_code=401, detail="éœ€è¦ Bearer Token è®¤è¯ã€‚")
        token = authorization.split(" ")[-1]
        if token != settings.API_MASTER_KEY:
            raise HTTPException(status_code=403, detail="æ— æ•ˆçš„ API Keyã€‚")

# --- API è·¯ç”± ---
@app.post("/v1/chat/completions", dependencies=[Depends(verify_api_key)])
async def chat_completions(request: Request):
    try:
        request_data = await request.json()
        logger.info(f"æ”¶åˆ°å®¢æˆ·ç«¯è¯·æ±‚ /v1/chat/completions:\n{json.dumps(request_data, indent=2, ensure_ascii=False)}")
        
        model_name = request_data.get("model", settings.DEFAULT_MODEL)
        if model_name == "nova-dalle3":
            messages = request_data.get("messages", [])
            last_user_message = next((m['content'] for m in reversed(messages) if m.get('role') == 'user'), None)
            if not last_user_message:
                raise HTTPException(status_code=400, detail="åœ¨ 'messages' ä¸­æœªæ‰¾åˆ°ç”¨æˆ·æ¶ˆæ¯ã€‚")

            image_request_data = {
                "prompt": last_user_message,
                "model": model_name,
                "n": 1,
                "size": "1:1",
                "response_format": "url"
            }
            image_result_dict = await provider.generate_image(image_request_data)
            image_url = image_result_dict.get("data", [{}])[0].get("url")
            if not image_url:
                raise HTTPException(status_code=502, detail="ä»ä¸Šæ¸¸æœåŠ¡ç”Ÿæˆå›¾åƒå¤±è´¥ã€‚")

            response_content = f"![{last_user_message[:30]}]({image_url})"
            chat_response = {
                "id": f"chatcmpl-{uuid.uuid4()}", "object": "chat.completion", "created": int(time.time()),
                "model": model_name,
                "choices": [{"index": 0, "message": {"role": "assistant", "content": response_content}, "finish_reason": "stop"}],
                "usage": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
            }
            return JSONResponse(content=chat_response)
        else:
            return await provider.chat_completion(request_data)

    except Exception as e:
        logger.error(f"å¤„ç†èŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}", exc_info=True)
        if isinstance(e, HTTPException):
            raise e
        raise HTTPException(status_code=500, detail=f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}")

@app.post("/v1/images/generations", dependencies=[Depends(verify_api_key)])
async def image_generations(request: Request):
    try:
        request_data = await request.json()
        logger.info(f"æ”¶åˆ°å®¢æˆ·ç«¯è¯·æ±‚ /v1/images/generations:\n{json.dumps(request_data, indent=2, ensure_ascii=False)}")
        image_result_dict = await provider.generate_image(request_data)
        return JSONResponse(content=image_result_dict)
    except Exception as e:
        logger.error(f"å¤„ç†å›¾åƒç”Ÿæˆè¯·æ±‚æ—¶å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}", exc_info=True)
        if isinstance(e, HTTPException):
            raise e
        raise HTTPException(status_code=500, detail=f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}")

@app.get("/v1/models", dependencies=[Depends(verify_api_key)], response_class=JSONResponse)
async def list_models():
    return await provider.get_models()

@app.get("/", response_class=HTMLResponse, include_in_schema=False)
async def serve_ui():
    try:
        with open("static/index.html", "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="UI æ–‡ä»¶ (static/index.html) æœªæ‰¾åˆ°ã€‚")

--- æ–‡ä»¶è·¯å¾„: nginx.conf ---

worker_processes auto;

events {
    worker_connections 1024;
}

http {
    upstream novaapp_backend {
        ip_hash;
        server app:8000;
    }

    server {
        listen 80;
        server_name localhost;

        location / {
            proxy_pass http://novaapp_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        
            # --- æ ¸å¿ƒä¿®æ”¹ç‚¹ï¼šå¢åŠ è¶…æ—¶è®¾ç½® ---
            proxy_connect_timeout 300s;
            proxy_send_timeout 300s;
            proxy_read_timeout 300s;

            proxy_buffering off;
            proxy_cache off;
            proxy_set_header Connection '';
            proxy_http_version 1.1;
            chunked_transfer_encoding off;
        }
    }
}

--- æ–‡ä»¶è·¯å¾„: requirements.txt ---

fastapi
uvicorn[standard]
pydantic-settings
python-dotenv
cloudscraper
loguru
httpx

--- æ–‡ä»¶è·¯å¾„: app\core\__init__.py ---



--- æ–‡ä»¶è·¯å¾„: app\core\config.py ---

import os
import logging
import uuid
from pydantic import BaseModel
from pydantic_settings import BaseSettings, SettingsConfigDict
from typing import List, Optional, Dict

logger = logging.getLogger(__name__)

class Credential(BaseModel):
    x_token: str
    x_user_id: str

class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding='utf-8',
        extra="ignore"
    )

    APP_NAME: str = "novaapp-2api"
    APP_VERSION: str = "2.0.0"
    DESCRIPTION: str = "ä¸€ä¸ªå°† NovaApp.ai è½¬æ¢ä¸ºå…¼å®¹ OpenAI æ ¼å¼ API çš„é«˜æ€§èƒ½ä»£ç†ï¼Œæ”¯æŒå¤šè´¦å·è½®è¯¢ã€æ–‡æœ¬ä¸å›¾åƒç”Ÿæˆã€‚"

    API_MASTER_KEY: Optional[str] = None
    NGINX_PORT: int = 8088
    API_REQUEST_TIMEOUT: int = 300
    POLLING_INTERVAL: int = 2
    POLLING_TIMEOUT: int = 240

    CREDENTIALS: List[Credential] = []

    CHAT_IMAGE_URL: str = "https://api.novaapp.ai/api/chat/image"
    IMAGE_GENERATOR_URL: str = "https://api.novaapp.ai/api/image-generator"
    IMAGE_BASE_URL: str = "https://firebasestorage.googleapis.com/v0/b/chat-ai-prod.appspot.com/o/"

    MODEL_MAPPING: Dict[str, int] = {
        "gpt-4o-mini": 0,
        "gpt-4o": 11,
        "gpt-5": 2,
        "gemini-flash": 10,
        "claude-3.5-sonnet": 15,
        "web-search": 14,
        "nova-dalle3": 4,
    }
    DEFAULT_MODEL: str = "gpt-4o-mini"

    def __init__(self, **values):
        super().__init__(**values)
        i = 1
        while True:
            cred_str = os.getenv(f"NOVAAPP_CREDENTIAL_{i}")
            if cred_str:
                try:
                    x_token, x_user_id = cred_str.split('|')
                    self.CREDENTIALS.append(Credential(x_token=x_token.strip(), x_user_id=x_user_id.strip()))
                except ValueError:
                    logger.warning(f"å‡­è¯æ ¼å¼é”™è¯¯ NOVAAPP_CREDENTIAL_{i}ï¼Œåº”ä¸º 'x_token|x_user_id'ã€‚")
                i += 1
            else:
                break
    
        if not self.CREDENTIALS:
            raise ValueError("å¿…é¡»åœ¨ .env æ–‡ä»¶ä¸­è‡³å°‘é…ç½®ä¸€ä¸ªæœ‰æ•ˆçš„ NOVAAPP_CREDENTIAL_1")

settings = Settings()

--- æ–‡ä»¶è·¯å¾„: app\providers\__init__.py ---



--- æ–‡ä»¶è·¯å¾„: app\providers\base_provider.py ---

# /app/providers/base_provider.py
from abc import ABC, abstractmethod
from typing import Dict, Any
from fastapi.responses import StreamingResponse, JSONResponse

class BaseProvider(ABC):
    @abstractmethod
    async def chat_completion(self, request_data: Dict[str, Any]) -> StreamingResponse:
        pass

    @abstractmethod
    async def get_models(self) -> JSONResponse:
        pass


--- æ–‡ä»¶è·¯å¾„: app\providers\novaapp_provider.py ---

import json
import time
import uuid
import threading
import asyncio
import base64
from typing import Dict, Any, AsyncGenerator, Tuple, List
from urllib.parse import quote

import cloudscraper
import httpx
from fastapi import HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
from loguru import logger

from app.core.config import settings, Credential
from app.utils.sse_utils import create_sse_data, create_chat_completion_chunk, DONE_CHUNK

# å®šä¹‰ä¸€ä¸ªé€šç”¨çš„ User-Agentï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36"

class NovaAppProvider:
    def __init__(self):
        self.scraper = cloudscraper.create_scraper()
        self.cred_manager = CredentialManager(settings.CREDENTIALS)
        # åˆ›å»ºä¸€ä¸ªå¯å¤ç”¨çš„ httpx å®¢æˆ·ç«¯å®ä¾‹
        self.http_client = httpx.AsyncClient()

    async def chat_completion(self, request_data: Dict[str, Any]) -> StreamingResponse:
        
        async def stream_generator() -> AsyncGenerator[bytes, None]:
            request_id = f"chatcmpl-{uuid.uuid4()}"
            model_name = request_data.get("model", settings.DEFAULT_MODEL)
            
            try:
                credential = self.cred_manager.get_credential()
                payload, model_id = self._prepare_chat_payload(request_data, model_name)
                headers = self._prepare_chat_headers(credential, model_id)

                logger.info(f"å‘ä¸Šæ¸¸å‘é€èŠå¤©è¯·æ±‚, æ¨¡å‹: {model_name} (ID: {payload['model']})")
                
                response = self.scraper.post(
                    "https://api.novaapp.ai/api/chat",
                    headers=headers,
                    json=payload,
                    stream=True,
                    timeout=settings.API_REQUEST_TIMEOUT
                )
                
                logger.info(f"ä¸Šæ¸¸å“åº”çŠ¶æ€ç : {response.status_code}")
                response.raise_for_status()

                for line in response.iter_lines():
                    if line.startswith(b"data:"):
                        content = line[len(b"data:"):].strip()
                        if content == b"[DONE]":
                            break
                        try:
                            data = json.loads(content)
                            delta_content = None
                            if "choices" in data:
                                choice = data.get("choices", [{}])[0]
                                if "delta" in choice:
                                    delta_content = choice.get("delta", {}).get("content")
                            
                            if delta_content is not None:
                                chunk = create_chat_completion_chunk(request_id, model_name, delta_content)
                                yield create_sse_data(chunk)
                        except (json.JSONDecodeError, IndexError):
                            if content:
                                logger.warning(f"æ— æ³•è§£æ SSE æ•°æ®å—: {content}")
                            continue
            
                final_chunk = create_chat_completion_chunk(request_id, model_name, "", "stop")
                yield create_sse_data(final_chunk)
                yield DONE_CHUNK

            except Exception as e:
                logger.error(f"å¤„ç†æµæ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
                error_message = f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}"
                error_chunk = create_chat_completion_chunk(request_id, model_name, error_message, "stop")
                yield create_sse_data(error_chunk)
                yield DONE_CHUNK

        return StreamingResponse(stream_generator(), media_type="text/event-stream")

    async def generate_image(self, request_data: Dict[str, Any]) -> Dict[str, Any]:
        prompt = request_data.get("prompt")
        if not prompt:
            raise HTTPException(status_code=400, detail="å‚æ•° 'prompt' ä¸èƒ½ä¸ºç©ºã€‚")

        model_name = request_data.get("model", "nova-dalle3")
        n = request_data.get("n", 1)

        try:
            initial_payload = {"messages": [{"role": "user", "content": prompt}]}
            model_id = settings.MODEL_MAPPING[model_name]
            credential = self.cred_manager.get_credential()
            headers = self._prepare_image_submit_headers(credential, model_id)
            
            logger.info(f"å‘ä¸Šæ¸¸æäº¤å›¾åƒç”Ÿæˆä»»åŠ¡, Prompt: '{prompt[:50]}...'")
            response = self.scraper.post(settings.CHAT_IMAGE_URL, headers=headers, json=initial_payload)
            response.raise_for_status()
            initial_data = response.json()

            image_tasks = initial_data.get("data", {}).get("images", [])
            if not image_tasks:
                raise Exception("ä¸Šæ¸¸ API æœªè¿”å›å›¾åƒä»»åŠ¡ã€‚")

            polling_tasks = []
            for task in image_tasks[:n]:
                polling_tasks.append(self._poll_single_image(task, credential))
            
            logger.info(f"å¼€å§‹å¹¶å‘è½®è¯¢ {len(polling_tasks)} ä¸ªå›¾åƒä»»åŠ¡...")
            final_urls = await asyncio.gather(*polling_tasks)

            logger.info(f"å¼€å§‹å¹¶å‘ä¸‹è½½ {len(final_urls)} å¼ å›¾ç‰‡å¹¶è½¬æ¢ä¸º Base64...")
            b64_tasks = [self._url_to_b64(url, credential) for url in final_urls]
            b64_results = await asyncio.gather(*b64_tasks)
            output_data = [{"b64_json": b64} for b64 in b64_results]
            logger.info("å›¾ç‰‡ Base64 è½¬æ¢å®Œæˆï¼Œè¿”å›ç»™å®¢æˆ·ç«¯ã€‚")

            return {"created": int(time.time()), "data": output_data}

        except Exception as e:
            logger.error(f"å›¾åƒç”Ÿæˆæµç¨‹å¤±è´¥: {e}", exc_info=True)
            raise HTTPException(status_code=502, detail=f"ä¸Šæ¸¸æœåŠ¡é”™è¯¯: {str(e)}")

    async def _poll_single_image(self, image_task: Dict[str, Any], credential: Credential) -> str:
        url = image_task.get("url")
        prompt = image_task.get("prompt")
        if not url or not prompt:
            raise ValueError("æ— æ•ˆçš„å›¾åƒä»»åŠ¡æ•°æ®ã€‚")

        payload = {"prompt": prompt, "url": url}
        headers = self._prepare_image_poll_headers(credential)
        
        start_time = time.time()
        while time.time() - start_time < settings.POLLING_TIMEOUT:
            try:
                response = self.scraper.post(settings.IMAGE_GENERATOR_URL, headers=headers, json=payload)
                response.raise_for_status()
                data = response.json()
                if data.get("isSuccess"):
                    relative_path = data["url"]
                    # æ‹¼æ¥å…ƒæ•°æ® URLï¼Œç”¨äºè·å– downloadTokens
                    metadata_url = f"{settings.IMAGE_BASE_URL}{quote(relative_path, safe='')}"
                    logger.success(f"ä»»åŠ¡ {url} æˆåŠŸï¼Œè·å–åˆ°å…ƒæ•°æ® URL: {metadata_url}")
                    return metadata_url
            except Exception as e:
                logger.warning(f"è½®è¯¢ä»»åŠ¡ {url} æ—¶å‡ºé”™: {e}")
            
            await asyncio.sleep(settings.POLLING_INTERVAL)
        
        raise Exception(f"è½®è¯¢ä»»åŠ¡ {url} è¶…æ—¶ã€‚")

    async def _url_to_b64(self, metadata_url: str, credential: Credential) -> str:
        # æ­¥éª¤1: è®¿é—®å…ƒæ•°æ® URL è·å– downloadTokens
        headers = {
            "Authorization": f"Firebase {credential.x_token}",
            "Origin": "https://chat.novaapp.ai",
            "Referer": "https://chat.novaapp.ai/",
            "User-Agent": USER_AGENT,
        }
        logger.info(f"æ­£åœ¨ä» {metadata_url} è·å–ä¸‹è½½ä»¤ç‰Œ...")
        meta_response = await self.http_client.get(metadata_url, headers=headers)
        meta_response.raise_for_status()
        meta_data = meta_response.json()
        token = meta_data.get("downloadTokens")
        if not token:
            raise ValueError("æ— æ³•ä»å…ƒæ•°æ®ä¸­æå– downloadTokensã€‚")
        logger.success(f"æˆåŠŸè·å–ä¸‹è½½ä»¤ç‰Œ: {token}")

        # æ­¥éª¤2: æ‹¼æ¥æœ€ç»ˆçš„ä¸‹è½½ URL å¹¶ä¸‹è½½å›¾ç‰‡
        final_download_url = f"{metadata_url}?alt=media&token={token}"
        logger.info(f"æ­£åœ¨ä»æœ€ç»ˆ URL ä¸‹è½½å›¾ç‰‡: {final_download_url}")
        image_response = await self.http_client.get(final_download_url, headers=headers)
        image_response.raise_for_status()
        
        return base64.b64encode(image_response.content).decode('utf-8')

    def _prepare_chat_headers(self, credential: Credential, model_id: int) -> Dict[str, str]:
        return {
            "Accept": "text/event-stream",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Content-Type": "application/json",
            "Origin": "https://chat.novaapp.ai",
            "Referer": "https://chat.novaapp.ai/",
            "User-Agent": USER_AGENT,
            "sec-ch-ua": '"Google Chrome";v="141", "Not?A_Brand";v="8", "Chromium";v="141"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "same-site",
            "x_token": credential.x_token,
            "x_user_id": credential.x_user_id,
            "x_platform": "web",
            "x_stream": "true",
            "x_pr": "true",
            "x_version": "2",
            "x_model": str(model_id),
        }

    def _prepare_image_submit_headers(self, credential: Credential, model_id: int) -> Dict[str, str]:
        return {
            "Accept": "*/*",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Content-Type": "application/json",
            "Origin": "https://chat.novaapp.ai",
            "Referer": "https://chat.novaapp.ai/",
            "User-Agent": USER_AGENT,
            "sec-ch-ua": '"Google Chrome";v="141", "Not?A_Brand";v="8", "Chromium";v="141"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "same-site",
            "x_token": credential.x_token,
            "x_user_id": credential.x_user_id,
            "x_platform": "web",
            "x_stream": "false",
            "x_pr": "true",
            "x_model": str(model_id),
        }

    def _prepare_image_poll_headers(self, credential: Credential) -> Dict[str, str]:
        return {
            "Accept": "*/*",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Content-Type": "application/json",
            "Origin": "https://chat.novaapp.ai",
            "Referer": "https://chat.novaapp.ai/",
            "User-Agent": USER_AGENT,
            "sec-ch-ua": '"Google Chrome";v="141", "Not?A_Brand";v="8", "Chromium";v="141"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "same-site",
            "x_token": credential.x_token,
            "x_user_id": credential.x_user_id,
            "x_platform": "web",
            "x_pr": "true",
            "x_source": "2",
        }

    def _prepare_chat_payload(self, request_data: Dict[str, Any], model_name: str) -> Tuple[Dict[str, Any], int]:
        model_id = settings.MODEL_MAPPING.get(model_name, settings.MODEL_MAPPING[settings.DEFAULT_MODEL])
        
        if 'stream_options' in request_data:
            del request_data['stream_options']

        payload = {
            "messages": request_data.get("messages", []),
            "model": model_id,
        }
        return payload, model_id

    async def get_models(self) -> JSONResponse:
        return JSONResponse(content={
            "object": "list",
            "data": [{"id": name, "object": "model", "created": int(time.time()), "owned_by": "lzA6"} for name in settings.MODEL_MAPPING.keys()]
        })

class CredentialManager:
    def __init__(self, credentials: list[Credential]):
        if not credentials:
            raise ValueError("å‡­è¯åˆ—è¡¨ä¸èƒ½ä¸ºç©ºã€‚")
        self.credentials = credentials
        self.lock = threading.Lock()
        self.current_index = 0

    def get_credential(self) -> Credential:
        with self.lock:
            cred = self.credentials[self.current_index]
            self.current_index = (self.current_index + 1) % len(self.credentials)
            logger.info(f"ä½¿ç”¨å‡­è¯ç´¢å¼•: {self.current_index}")
            return cred

--- æ–‡ä»¶è·¯å¾„: app\utils\sse_utils.py ---

import json
import time
from typing import Dict, Any, Optional

DONE_CHUNK = b"data: [DONE]\n\n"

def create_sse_data(data: Dict[str, Any]) -> bytes:
    return f"data: {json.dumps(data)}\n\n".encode('utf-8')

def create_chat_completion_chunk(
    request_id: str,
    model: str,
    content: str,
    finish_reason: Optional[str] = None
) -> Dict[str, Any]:
    return {
        "id": request_id,
        "object": "chat.completion.chunk",
        "created": int(time.time()),
        "model": model,
        "choices": [
            {
                "index": 0,
                "delta": {"content": content},
                "finish_reason": finish_reason
            }
        ]
    }

--- æ–‡ä»¶è·¯å¾„: static\index.html ---

<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NovaApp-2API å›¾åƒç”Ÿæˆé¢æ¿</title>
    <link rel="stylesheet" href="/static/style.css">
</head>
<body>
    <div class="container">
        <div class="sidebar">
            <div class="header">
                <h2>NovaApp-2API</h2>
                <p>v2.0.0 - å›¾åƒç”Ÿæˆ</p>
            </div>

            <div class="form-group">
                <label for="api-key">API Key</label>
                <input type="password" id="api-key" placeholder="è¯·è¾“å…¥æ‚¨çš„ API Key" value="1">
            </div>

            <div class="form-group">
                <label for="prompt-input">æç¤ºè¯ (Prompt)</label>
                <textarea id="prompt-input" rows="8" placeholder="è¾“å…¥æ‚¨çš„å›¾åƒæè¿°..."></textarea>
            </div>

            <div class="form-group">
                <label for="ratio-select">æ¯”ä¾‹ (Ratio)</label>
                <select id="ratio-select">
                    <option value="1:1" selected>1:1 (æ–¹å½¢)</option>
                    <option value="3:2">3:2 (æ¨ªå±)</option>
                    <option value="2:3">2:3 (ç«–å±)</option>
                </select>
            </div>

            <div class="form-group slider-group">
                <div class="slider-label">
                    <label for="count-slider">ç”Ÿæˆæ•°é‡ (Count)</label>
                    <span id="count-value">2</span>
                </div>
                <input type="range" id="count-slider" min="1" max="4" step="1" value="2">
            </div>

            <button id="generate-btn">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="icon"><path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm.75-11.25a.75.75 0 00-1.5 0v2.5h-2.5a.75.75 0 000 1.5h2.5v2.5a.75.75 0 001.5 0v-2.5h2.5a.75.75 0 000-1.5h-2.5v-2.5z" clip-rule="evenodd" /></svg>
                <span>ç”Ÿæˆå›¾åƒ</span>
            </button>
        </div>
        <div class="main-content">
            <div id="result-panel">
                <div id="placeholder" class="placeholder">
                    <p>è¯·åœ¨å·¦ä¾§é…ç½®å‚æ•°å¹¶å¼€å§‹ç”Ÿæˆ</p>
                </div>
                <div id="spinner" class="spinner hidden"></div>
                <div id="error-message" class="error hidden"></div>
                <div id="image-grid"></div>
            </div>
        </div>
    </div>
    <script src="/static/script.js"></script>
</body>
</html>

--- æ–‡ä»¶è·¯å¾„: static\script.js ---

document.addEventListener('DOMContentLoaded', () => {
    const apiKeyInput = document.getElementById('api-key');
    const ratioSelect = document.getElementById('ratio-select');
    const promptInput = document.getElementById('prompt-input');
    const generateBtn = document.getElementById('generate-btn');
    const countSlider = document.getElementById('count-slider');
    const countValue = document.getElementById('count-value');
    const imageGrid = document.getElementById('image-grid');
    const spinner = document.getElementById('spinner');
    const errorMessage = document.getElementById('error-message');
    const placeholder = document.getElementById('placeholder');

    async function handleGenerate() {
        const apiKey = apiKeyInput.value.trim();
        const prompt = promptInput.value.trim();

        if (!apiKey || !prompt) {
            showError("è¯·ç¡®ä¿ API Key å’Œæç¤ºè¯éƒ½å·²å¡«å†™ã€‚");
            return;
        }

        setLoading(true);

        // æ³¨æ„ï¼šè™½ç„¶æˆ‘ä»¬åœ¨è¿™é‡Œè¯·æ±‚ b64_jsonï¼Œä½†åç«¯å·²è¢«ä¿®æ”¹ä¸ºæ€»æ˜¯è¿”å› b64_json
        const payload = {
            model: "nova-dalle3",
            prompt: prompt,
            n: parseInt(countSlider.value, 10),
            size: ratioSelect.value,
            response_format: "b64_json" 
        };

        try {
            const response = await fetch('/v1/images/generations', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${apiKey}`
                },
                body: JSON.stringify(payload)
            });

            const result = await response.json();
            if (!response.ok) {
                throw new Error(result.detail || 'ç”Ÿæˆå¤±è´¥ï¼ŒæœªçŸ¥é”™è¯¯ã€‚');
            }

            if (result.data && result.data.length > 0) {
                displayImages(result.data);
            } else {
                throw new Error('API è¿”å›äº†æˆåŠŸçŠ¶æ€ï¼Œä½†æ²¡æœ‰å›¾ç‰‡æ•°æ®ã€‚');
            }
        } catch (error) {
            showError(error.message);
        } finally {
            setLoading(false);
        }
    }

    function displayImages(data) {
        imageGrid.innerHTML = '';
        data.forEach(item => {
            // --- æ ¸å¿ƒä¿®æ”¹ç‚¹ ---
            // æ£€æŸ¥ item.b64_json è€Œä¸æ˜¯ item.url
            if (item.b64_json) {
                const imgContainer = document.createElement('div');
                imgContainer.className = 'image-container';
                const img = document.createElement('img');
                // ä½¿ç”¨ Data URL æ ¼å¼æ¥æ˜¾ç¤º Base64 å›¾ç‰‡
                img.src = 'data:image/jpeg;base64,' + item.b64_json;
                img.alt = 'Generated Image';
                imgContainer.appendChild(img);
                imageGrid.appendChild(imgContainer);
            }
        });
    }

    function setLoading(isLoading) {
        generateBtn.disabled = isLoading;
        spinner.classList.toggle('hidden', !isLoading);
        placeholder.classList.toggle('hidden', isLoading || imageGrid.children.length > 0);
        if (isLoading) {
            imageGrid.innerHTML = '';
            hideError();
        }
    }

    function showError(message) {
        errorMessage.textContent = `é”™è¯¯: ${message}`;
        errorMessage.classList.remove('hidden');
        imageGrid.innerHTML = '';
        placeholder.classList.add('hidden');
    }

    function hideError() {
        errorMessage.classList.add('hidden');
    }

    countSlider.addEventListener('input', () => countValue.textContent = countSlider.value);
    generateBtn.addEventListener('click', handleGenerate);
});

--- æ–‡ä»¶è·¯å¾„: static\style.css ---

:root {
    --bg-color: #f0f2f5;
    --sidebar-bg: #ffffff;
    --main-bg: #f7f7f8;
    --preview-bg: #ffffff;
    --border-color: #e5e7eb;
    --text-color: #111827;
    --text-secondary: #6b7280;
    --primary-color: #4f46e5;
    --primary-hover: #4338ca;
    --input-bg: #f9fafb;
    --error-color: #ef4444;
}

* { box-sizing: border-box; }

body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    margin: 0;
    background-color: var(--bg-color);
    color: var(--text-color);
    font-size: 14px;
    display: flex;
    height: 100vh;
    overflow: hidden;
}

.container { display: flex; width: 100%; height: 100%; }

.sidebar {
    width: 350px;
    flex-shrink: 0;
    background-color: var(--sidebar-bg);
    border-right: 1px solid var(--border-color);
    padding: 24px;
    display: flex;
    flex-direction: column;
    overflow-y: auto;
}

.header { padding-bottom: 16px; margin-bottom: 24px; border-bottom: 1px solid var(--border-color); }
.header h2 { margin: 0; }
.header p { margin: 4px 0 0; color: var(--text-secondary); }

.main-content {
    flex-grow: 1;
    background-color: var(--main-bg);
    padding: 24px;
    overflow-y: auto;
}

#result-panel {
    width: 100%;
    height: 100%;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
}

.form-group { margin-bottom: 20px; }
label { display: block; font-weight: 500; margin-bottom: 8px; }

input[type="password"], textarea, select {
    width: 100%;
    padding: 10px 12px;
    border: 1px solid var(--border-color);
    border-radius: 6px;
    font-size: 14px;
    background-color: var(--input-bg);
    transition: border-color 0.2s;
}
textarea { resize: vertical; }
input:focus, textarea:focus, select:focus {
    outline: none;
    border-color: var(--primary-color);
    box-shadow: 0 0 0 2px rgba(99, 102, 241, 0.2);
}

.slider-group .slider-label {
    display: flex;
    justify-content: space-between;
    align-items: center;
}
.slider-group .slider-label span {
    font-weight: 600;
    color: var(--primary-color);
}

input[type="range"] {
    -webkit-appearance: none;
    width: 100%;
    height: 6px;
    background: #ddd;
    border-radius: 5px;
    outline: none;
    margin-top: 8px;
}
input[type="range"]::-webkit-slider-thumb {
    -webkit-appearance: none;
    appearance: none;
    width: 18px;
    height: 18px;
    background: var(--primary-color);
    cursor: pointer;
    border-radius: 50%;
}

#generate-btn {
    width: 100%;
    padding: 12px;
    background-color: var(--primary-color);
    color: white;
    border: none;
    border-radius: 6px;
    font-size: 16px;
    font-weight: 500;
    cursor: pointer;
    transition: background-color 0.2s;
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 8px;
    margin-top: auto;
}
#generate-btn:hover { background-color: var(--primary-hover); }
#generate-btn:disabled { background-color: #9ca3af; cursor: not-allowed; }
#generate-btn .icon { width: 20px; height: 20px; }

.placeholder {
    text-align: center;
    color: var(--text-secondary);
}

#image-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(256px, 1fr));
    gap: 16px;
    width: 100%;
}
.image-container {
    position: relative;
    overflow: hidden;
    border-radius: 8px;
    box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    aspect-ratio: 1 / 1;
}
.image-container img {
    width: 100%;
    height: 100%;
    object-fit: cover;
    display: block;
}

.hidden { display: none; }

.spinner {
    border: 5px solid rgba(0, 0, 0, 0.1);
    width: 50px;
    height: 50px;
    border-radius: 50%;
    border-left-color: var(--primary-color);
    animation: spin 1s ease infinite;
}
@keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }

.error {
    color: #b91c1c;
    background-color: #fee2e2;
    border: 1px solid #fca5a5;
    padding: 15px;
    border-radius: 6px;
    text-align: center;
    max-width: 600px;
}


